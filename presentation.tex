% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  ignorenonframetext,
]{beamer}
\usepackage{pgfpages}
\setbeamertemplate{caption}[numbered]
\setbeamertemplate{caption label separator}{: }
\setbeamercolor{caption name}{fg=normal text.fg}
\beamertemplatenavigationsymbolsempty
% Prevent slide breaks in the middle of a paragraph
\widowpenalties 1 10000
\raggedbottom
\setbeamertemplate{part page}{
  \centering
  \begin{beamercolorbox}[sep=16pt,center]{part title}
    \usebeamerfont{part title}\insertpart\par
  \end{beamercolorbox}
}
\setbeamertemplate{section page}{
  \centering
  \begin{beamercolorbox}[sep=12pt,center]{part title}
    \usebeamerfont{section title}\insertsection\par
  \end{beamercolorbox}
}
\setbeamertemplate{subsection page}{
  \centering
  \begin{beamercolorbox}[sep=8pt,center]{part title}
    \usebeamerfont{subsection title}\insertsubsection\par
  \end{beamercolorbox}
}
\AtBeginPart{
  \frame{\partpage}
}
\AtBeginSection{
  \ifbibliography
  \else
    \frame{\sectionpage}
  \fi
}
\AtBeginSubsection{
  \frame{\subsectionpage}
}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\newif\ifbibliography
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\usepackage{graphicx}
\usepackage{float}
\usepackage{subfigure}
\usepackage{algorithm}
\usepackage{algpseudocode}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Breast Cancer Diagnosis}
\author{Hongjie Liu, Xicheng Xie, Jiajun Tao, Shaohan Chen, Yujia Li}
\date{2023-02-27}

\begin{document}
\frame{\titlepage}

\begin{frame}{Outline}
\protect\hypertarget{outline}{}
\begin{itemize}
\item
  Background
\item
  Task 1
\item
  Task 2
\item
  Task 3
\item
  Task 4
\item
  Discussions
\item
  Limitations and Future Work
\item
  Reference
\item
  Q\&A
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Background}
\protect\hypertarget{background}{}
\begin{itemize}
\tightlist
\item
  The data is the breast cancer medical data retrieved from
  ``breast-cancer.csv'', which have 569 row and 33 columns.\\
\item
  The first column \texttt{ID} labels individual breast tissue images;
  The second column \texttt{Diagnonsis} identifies if the image is
  coming from cancer tissue or benign cases (M=malignant, B = benign).
  There are 357 benign and 212 malignant cases.
\item
  The other 30 columns correspond to mean, standard deviation and the
  largest values (points on the tails) of the distributions of the
  following 10 features computed for the cellnuclei;
\end{itemize}
\end{frame}

\begin{frame}{Objectives}
\protect\hypertarget{objectives}{}
\begin{itemize}
\item
  The goal of the exercise is to build a predictive model based on
  logistic regression to facilitate cancer diagnosis.
\item
  We will move towards the goal with the steps of task 1,2,3 and 4.
\end{itemize}
\end{frame}

\begin{frame}{Task 1}
\protect\hypertarget{task-1}{}
\textbf{Objective}

Build a logistic model to classify the images into malignant/benign, and
write down your likelihood function, its gradient and Hessian matrix.
\end{frame}

\begin{frame}{Task 1 - Build a logistic model}
\protect\hypertarget{task-1---build-a-logistic-model}{}
Define the ``Diagnosis'' variable will be coded as 1 for malignant cases
and 0 for benign cases.

\par

Given \(n\) i.i.d. observations with \(p\) predictors, we consider a
logistic regression model \begin{equation}\label{model}
P(Y_i=1\mid \mathbf{x}_i)=\frac{e^{\mathbf{x}_i^\top\boldsymbol{\beta}}}{1+e^{\mathbf{x}_i^\top\boldsymbol{\beta}}},\; i=1,\ldots,n
\end{equation} where
\(\boldsymbol{\beta}=(\beta_0,\beta_1,\ldots,\beta_p)^\top\in\mathbb{R}^{p+1}\)
is the parameter vector, \(\mathbf{x}_i=(1,X_{i1},\ldots,X_{ip})^\top\)
is the vector of predictors in the \(i\)-th observation, and
\(Y_i\in\{0,1\}\) is the binary response in the \(i\)-th observation.
\end{frame}

\begin{frame}{Task 1 - Build a logistic model}
\protect\hypertarget{task-1---build-a-logistic-model-1}{}
Let \(\mathbf{y}=(Y_1,Y_2,\ldots,Y_n)^\top\) denote the response vector,
\(\mathbf{X}=(\mathbf{x}_1,\mathbf{x}_2,\ldots,\mathbf{x}_n)^\top\in\mathbb{R}^{n\times(p+1)}\)
denote the design matrix. The observed likelihood of
\(\{(Y_1,\mathbf{x}_1),(Y_2,\mathbf{x}_2)\ldots,(Y_n,\mathbf{x}_n)\}\)
is
\[L(\boldsymbol{\beta};\mathbf{y},\mathbf{X})=\prod_{i=1}^n\left[\left(\frac{e^{\mathbf{x}_i^\top\boldsymbol{\beta}}}{1+e^{\mathbf{x}_i^\top\boldsymbol{\beta}}}\right)^{Y_i}\left(\frac{1}{1+e^{\mathbf{x}_i^\top\boldsymbol{\beta}}}\right)^{1-Y_i}\right].\]
\end{frame}

\begin{frame}{Task 1 - Build a logistic model}
\protect\hypertarget{task-1---build-a-logistic-model-2}{}
Maximizing the likelihood is equivalent to maximizing the log-likelihood
function: \begin{equation}\label{func}
f(\boldsymbol{\beta};\mathbf{y},\mathbf{X})=\sum_{i=1}^n\left[Y_i\mathbf{x}_i^\top\boldsymbol{\beta}-\log\left(1+e^{\mathbf{x}_i^\top\boldsymbol{\beta}}\right)\right].
\end{equation} The estimates of model parameters are
\[\widehat{\boldsymbol{\beta}}=\arg\max_{\boldsymbol{\beta}}\; f(\boldsymbol{\beta};\mathbf{y},\mathbf{X}),\]
and the optimization problem is \begin{equation}\label{opt}
\max_{\boldsymbol{\beta}}\; f(\boldsymbol{\beta};\mathbf{y},\mathbf{X}).
\end{equation}
\end{frame}

\begin{frame}{Task 1 - Build a logistic model}
\protect\hypertarget{task-1---build-a-logistic-model-3}{}
Denote \(p_i=P(Y_i=1\mid\mathbf{x}_i)\) as given in (\ref{model}) and
\(\mathbf{p}=(p_1,p_2,\ldots,p_n)^\top\). The gradient of \(f\) is
\begin{align*}
\nabla f(\boldsymbol{\beta};\mathbf{y},\mathbf{X})&=\mathbf{X}^\top(\mathbf{y}-\mathbf{p})\\
&=\sum_{i=1}^n(Y_i-p_i)\mathbf{x}_i\\
&=\begin{pmatrix}
\sum_{i=1}^n(Y_i-p_i)\\ \sum_{i=1}^n(Y_i-p_i)X_{i1}\\ \vdots\\ \sum_{i=1}^n(Y_i-p_i)X_{ip}\end{pmatrix}.
\end{align*}
\end{frame}

\begin{frame}{Task 1 - Build a logistic model}
\protect\hypertarget{task-1---build-a-logistic-model-4}{}
Denote \(w_i=p_i(1-p_i)\in(0,1)\) and
\(\mathbf{W}=\mathrm{diag}(w_1,\ldots,w_n)\). The Hessian matrix of
\(f\) is given by \begin{align*}
\nabla^2 f(\boldsymbol{\beta};\mathbf{y},\mathbf{X})&=-\mathbf{X}^\top\mathbf{W}\mathbf{X}\\
&=-\sum_{i=1}^nw_i\mathbf{x}_i\mathbf{x}_i^\top\\
&=-\begin{pmatrix}
\sum_{i=1}^nw_i & \sum_{i=1}^nw_iX_{i1} & \cdots & \sum_{i=1}^nw_iX_{i1} \\ 
\sum_{i=1}^nw_iX_{i1} & \sum_{i=1}^nw_iX_{i1}^2 & \cdots & \sum_{i=1}^nw_iX_{i1}X_{ip} \\ 
\vdots & \vdots & \ddots & \vdots \\ 
\sum_{i=1}^nw_iX_{ip} & \sum_{i=1}^nw_iX_{in}X_{i1} & \cdots & \sum_{i=1}^nw_iX_{ip}^2
\end{pmatrix}.
\end{align*}
\end{frame}

\begin{frame}{Task 1 - Build a logistic model}
\protect\hypertarget{task-1---build-a-logistic-model-5}{}
Next, we show that the Hessian matrix
\(\nabla^2 f(\boldsymbol{\beta};\mathbf{y},\mathbf{X})\) is a
negative-definite matrix if \(\mathbf{X}\) has full rank.

\textbf{\emph{Proof.}} For any \((p+1)\)-dimensional nonzero vector
\(\boldsymbol{\alpha}\), given that \(\mathbf{X}\) has full rank,
\(\mathbf{X}\boldsymbol{\alpha}\) is also a nonzero vector. Since
\(\mathbf{W}\) is positive-definite, we have \begin{align*}
\boldsymbol{\alpha}^\top\nabla^2 f(\boldsymbol{\beta};\mathbf{y},\mathbf{X})\boldsymbol{\alpha}&=\boldsymbol{\alpha}^\top(-\mathbf{X}^\top\mathbf{W}\mathbf{X})\boldsymbol{\alpha}\\
&=-(\mathbf{X}\boldsymbol{\alpha})^\top\mathbf{W}(\mathbf{X}\boldsymbol{\alpha})\\
&<0.
\end{align*} Thus,
\(\nabla^2 f(\boldsymbol{\beta};\mathbf{y},\mathbf{X})\) is
negative-definite. \hfill\(\square\)

Hence, the optimization problem (\ref{opt}) is a well-defined problem.
\end{frame}

\begin{frame}{Task 2}
\protect\hypertarget{task-2}{}
\textbf{Objective}

Develop a Newton-Raphson algorithm to estimate your model
\end{frame}

\begin{frame}{Task 2 - Newton-Raphson algorithm}
\protect\hypertarget{task-2---newton-raphson-algorithm}{}
The target function \(f\) given in task 1: \begin{equation}\label{func}
f(\boldsymbol{\beta};\mathbf{y},\mathbf{X})=\sum_{i=1}^n\left[Y_i\mathbf{x}_i^\top\boldsymbol{\beta}-\log\left(1+e^{\mathbf{x}_i^\top\boldsymbol{\beta}}\right)\right].
\end{equation}
\end{frame}

\begin{frame}{Task 2 - Newton-Raphson algorithm}
\protect\hypertarget{task-2---newton-raphson-algorithm-1}{}
\end{frame}

\begin{frame}[fragile]{Task 2 - Newton-Raphson algorithm}
\protect\hypertarget{task-2---newton-raphson-algorithm-2}{}
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{NewtonRaphson }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(dat, func, start, }\AttributeTok{tol =} \FloatTok{1e{-}8}\NormalTok{, }\AttributeTok{maxiter =} \DecValTok{200}\NormalTok{) \{}
\NormalTok{  i }\OtherTok{\textless{}{-}} \DecValTok{0}
\NormalTok{  cur }\OtherTok{\textless{}{-}}\NormalTok{ start}
\NormalTok{  stuff }\OtherTok{\textless{}{-}} \FunctionTok{func}\NormalTok{(dat, cur)}
\NormalTok{  res }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, stuff}\SpecialCharTok{$}\NormalTok{f, cur)}
\NormalTok{  prevf }\OtherTok{\textless{}{-}} \SpecialCharTok{{-}}\ConstantTok{Inf}
\NormalTok{  X }\OtherTok{\textless{}{-}} \FunctionTok{cbind}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, }\FunctionTok{nrow}\NormalTok{(dat)), }\FunctionTok{as.matrix}\NormalTok{(dat[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{]))}
\NormalTok{  y }\OtherTok{\textless{}{-}}\NormalTok{ dat[, }\DecValTok{1}\NormalTok{]}
\NormalTok{  warned }\OtherTok{\textless{}{-}} \DecValTok{0}
  \ControlFlowTok{while}\NormalTok{ (}\FunctionTok{abs}\NormalTok{(stuff}\SpecialCharTok{$}\NormalTok{f }\SpecialCharTok{{-}}\NormalTok{ prevf) }\SpecialCharTok{\textgreater{}}\NormalTok{ tol }\SpecialCharTok{\&\&}\NormalTok{ i }\SpecialCharTok{\textless{}}\NormalTok{ maxiter) \{}
\NormalTok{    i }\OtherTok{\textless{}{-}}\NormalTok{ i }\SpecialCharTok{+} \DecValTok{1}
\NormalTok{    prevf }\OtherTok{\textless{}{-}}\NormalTok{ stuff}\SpecialCharTok{$}\NormalTok{f}
\NormalTok{    prev }\OtherTok{\textless{}{-}}\NormalTok{ cur}
\NormalTok{    d }\OtherTok{\textless{}{-}} \SpecialCharTok{{-}}\FunctionTok{solve}\NormalTok{(stuff}\SpecialCharTok{$}\NormalTok{Hess) }\SpecialCharTok{\%*\%}\NormalTok{ stuff}\SpecialCharTok{$}\NormalTok{grad}
\NormalTok{    cur }\OtherTok{\textless{}{-}}\NormalTok{ prev }\SpecialCharTok{+}\NormalTok{ d}
\NormalTok{    lambda }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{    maxhalv }\OtherTok{\textless{}{-}} \DecValTok{0}
    \ControlFlowTok{while}\NormalTok{ (}\FunctionTok{func}\NormalTok{(dat, cur)}\SpecialCharTok{$}\NormalTok{f }\SpecialCharTok{\textless{}}\NormalTok{ prevf }\SpecialCharTok{\&\&}\NormalTok{ maxhalv }\SpecialCharTok{\textless{}} \DecValTok{50}\NormalTok{) \{}
\NormalTok{      maxhalv }\OtherTok{\textless{}{-}}\NormalTok{ maxhalv }\SpecialCharTok{+} \DecValTok{1}
\NormalTok{      lambda }\OtherTok{\textless{}{-}}\NormalTok{ lambda }\SpecialCharTok{/} \DecValTok{2}
\NormalTok{      cur }\OtherTok{\textless{}{-}}\NormalTok{ prev }\SpecialCharTok{+}\NormalTok{ lambda }\SpecialCharTok{*}\NormalTok{ d}
\NormalTok{    \}}
\NormalTok{    stuff }\OtherTok{\textless{}{-}} \FunctionTok{func}\NormalTok{(dat, cur)}
\NormalTok{    res }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(res, }\FunctionTok{c}\NormalTok{(i, stuff}\SpecialCharTok{$}\NormalTok{f, cur))}
\NormalTok{    y\_hat }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(X }\SpecialCharTok{\%*\%}\NormalTok{ cur }\SpecialCharTok{\textgreater{}} \DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
    \ControlFlowTok{if}\NormalTok{ (warned }\SpecialCharTok{==} \DecValTok{0} \SpecialCharTok{\&\&} \FunctionTok{sum}\NormalTok{(y }\SpecialCharTok{{-}}\NormalTok{ y\_hat) }\SpecialCharTok{==} \DecValTok{0}\NormalTok{) \{}
      \FunctionTok{warning}\NormalTok{(}\StringTok{"Complete separation occurs. Algorithm does not converge."}\NormalTok{)}
\NormalTok{      warned }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{    \}}
\NormalTok{  \}}
  \FunctionTok{colnames}\NormalTok{(res) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"iter"}\NormalTok{, }\StringTok{"target\_function"}\NormalTok{, }\StringTok{"(Intercept)"}\NormalTok{, }\FunctionTok{names}\NormalTok{(dat)[}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{])}
  \FunctionTok{return}\NormalTok{(res)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}
\end{frame}

\begin{frame}[fragile]{Task 2 - Newton-Raphson algorithm}
\protect\hypertarget{task-2---newton-raphson-algorithm-3}{}
\textbf{Data preprocessing and data partition.}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bc\_df }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"breast{-}cancer.csv"}\NormalTok{)[}\SpecialCharTok{{-}}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{33}\NormalTok{)] }\SpecialCharTok{\%\textgreater{}\%} \CommentTok{\# remove variable ID and an NA column}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{diagnosis =} \FunctionTok{ifelse}\NormalTok{(diagnosis }\SpecialCharTok{==} \StringTok{"M"}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)) }\CommentTok{\# code malignant cases as 1}
\NormalTok{bc\_df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}} \FunctionTok{scale}\NormalTok{(bc\_df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{]) }\CommentTok{\# predictors are standardized for the logistic{-}LASSO model in task 3}

\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{indexTrain }\OtherTok{\textless{}{-}} \FunctionTok{createDataPartition}\NormalTok{(}\AttributeTok{y =}\NormalTok{ bc\_df}\SpecialCharTok{$}\NormalTok{diagnosis, }\AttributeTok{p =} \FloatTok{0.8}\NormalTok{, }\AttributeTok{list =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{Training }\OtherTok{\textless{}{-}}\NormalTok{ bc\_df[indexTrain, ]}
\NormalTok{Test }\OtherTok{\textless{}{-}}\NormalTok{ bc\_df[}\SpecialCharTok{{-}}\NormalTok{indexTrain, ]}

\FunctionTok{glm}\NormalTok{(diagnosis }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{family =} \FunctionTok{binomial}\NormalTok{(}\AttributeTok{link =} \StringTok{"logit"}\NormalTok{), }\AttributeTok{data =}\NormalTok{ Training)}

\NormalTok{logisticstuff }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(dat, betavec) \{}
\NormalTok{  dat }\OtherTok{\textless{}{-}} \FunctionTok{as.matrix}\NormalTok{(dat)}
\NormalTok{  n }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(dat)}
\NormalTok{  p }\OtherTok{\textless{}{-}} \FunctionTok{ncol}\NormalTok{(dat) }\SpecialCharTok{{-}} \DecValTok{1}
\NormalTok{  X }\OtherTok{\textless{}{-}} \FunctionTok{cbind}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, n), dat[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{]) }\CommentTok{\# design matrix}
\NormalTok{  y }\OtherTok{\textless{}{-}}\NormalTok{ dat[, }\DecValTok{1}\NormalTok{] }\CommentTok{\# response vector}
\NormalTok{  u }\OtherTok{\textless{}{-}}\NormalTok{ X }\SpecialCharTok{\%*\%}\NormalTok{ betavec }\CommentTok{\# x\_i\^{}T beta, i=1,...,n}
\NormalTok{  f }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(y }\SpecialCharTok{*}\NormalTok{ u }\SpecialCharTok{{-}} \FunctionTok{log1pexp}\NormalTok{(u)) }\CommentTok{\# function \textasciigrave{}log1pexp\textasciigrave{} to compute log(1 + exp(x)))}
\NormalTok{  p\_vec }\OtherTok{\textless{}{-}} \FunctionTok{sigmoid}\NormalTok{(u) }\CommentTok{\# function \textasciigrave{}sigmoid\textasciigrave{} to compute exp(x)/(1 + exp(x))}
\NormalTok{  grad }\OtherTok{\textless{}{-}} \FunctionTok{t}\NormalTok{(X) }\SpecialCharTok{\%*\%}\NormalTok{ (y }\SpecialCharTok{{-}}\NormalTok{ p\_vec)}
\NormalTok{  Hess }\OtherTok{\textless{}{-}} \SpecialCharTok{{-}}\FunctionTok{t}\NormalTok{(X) }\SpecialCharTok{\%*\%} \FunctionTok{diag}\NormalTok{(}\FunctionTok{c}\NormalTok{(p\_vec }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ p\_vec))) }\SpecialCharTok{\%*\%}\NormalTok{ X}
  \FunctionTok{return}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\AttributeTok{f =}\NormalTok{ f, }\AttributeTok{grad =}\NormalTok{ grad, }\AttributeTok{Hess =}\NormalTok{ Hess))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}
\end{frame}

\hypertarget{task-2---newton-raphson-algorithm-4}{%
\section{Task 2 - Newton-Raphson
algorithm}\label{task-2---newton-raphson-algorithm-4}}

\begin{frame}{Task 3}
\protect\hypertarget{task-3}{}
\end{frame}

\begin{frame}{Task 4}
\protect\hypertarget{task-4}{}
\end{frame}

\begin{frame}{Discussions}
\protect\hypertarget{discussions}{}
\begin{itemize}
\item
  There is much freedom when designing the simulations.
\item
  In our algorithm, we have 5 parameters. n, p, ratio, c, corr
\item
  More parameters can be adjusted.
\end{itemize}
\end{frame}

\begin{frame}{Limitations and Future Work}
\protect\hypertarget{limitations-and-future-work}{}
\begin{itemize}
\item
  Limitation: We reproduced high-dimensional scenarios, but we still
  don't know the solution.
\item
  Future Work: We may adjust other parameters to investigate further.
\end{itemize}
\end{frame}

\begin{frame}{Reference}
\protect\hypertarget{reference}{}
\begin{enumerate}
\tightlist
\item
  Li Y, Hong HG, Ahmed SE, Li Y. Weak signals in high‐dimensional
  regression: Detection, estimation and prediction. Appl Stochastic
  Models Bus Ind. 2018;1--16. \url{https://doi.org/10.1002/asmb.2340}
\end{enumerate}
\end{frame}

\begin{frame}{Q\&A}
\protect\hypertarget{qa}{}
\begin{itemize}
\item
  Thanks for listening!
\item
  Any questions?
\end{itemize}
\end{frame}

\end{document}
